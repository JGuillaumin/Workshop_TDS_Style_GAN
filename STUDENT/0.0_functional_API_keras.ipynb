{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to the Keras Functional API\n",
    "\n",
    "- Sequential API : one imput, one output, one 'path' within the network !\n",
    "\n",
    "With the **Functional API** :\n",
    "- multiple inputs\n",
    "- multiple outputs\n",
    "- multiple pathes within the network ('Network in Network', 'Residual Block', 'Inception block')\n",
    "- useful when reusing pre-trained networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application : image classification with MNIST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some datasets are available directly with Keras\n",
    "from keras.datasets.mnist import load_data\n",
    "\n",
    "# train/val/test\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, shuffle=True, stratify=y_train, test_size=0.2)\n",
    "\n",
    "print(\"x_train : {} | {}\".format(x_train.shape, x_train.dtype))\n",
    "print(\"y_train : {} | {}\".format(y_train.shape, y_train.dtype))\n",
    "print(\"x_val : {} | {}\".format(x_val.shape, x_val.dtype))\n",
    "print(\"y_val : {} | {}\".format(y_val.shape, y_val.dtype))\n",
    "print(\"x_test : {} | {}\".format(x_test.shape, x_test.dtype))\n",
    "print(\"y_test : {} | {}\".format(y_test.shape, y_test.dtype))\n",
    "_ = plt.hist(y_train, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "for id_class in range(10):\n",
    "    indices = np.where(y_train==id_class)[0]\n",
    "    for i in range(10):\n",
    "        plt.subplot(10, 10, id_class*10 + i + 1)\n",
    "        plt.imshow(x_train[indices[i]], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimal pre-processsing \n",
    "# add new 'dim' : channel dimension \n",
    "x_train = np.expand_dims(x_train, axis=-1).astype(np.float32) / 255.\n",
    "x_val = np.expand_dims(x_val, axis=-1).astype(np.float32) / 255.\n",
    "x_test = np.expand_dims(x_test, axis=-1).astype(np.float32) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding for the labels\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train,num_classes=10)\n",
    "y_val = to_categorical(y_val,num_classes=10)\n",
    "y_test = to_categorical(y_test,num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x_train : {} | {}\".format(x_train.shape, x_train.dtype))\n",
    "print(\"y_train : {} | {}\".format(y_train.shape, y_train.dtype))\n",
    "print(\"x_val : {} | {}\".format(x_val.shape, x_val.dtype))\n",
    "print(\"y_val : {} | {}\".format(y_val.shape, y_val.dtype))\n",
    "print(\"x_test : {} | {}\".format(x_test.shape, x_test.dtype))\n",
    "print(\"y_test : {} | {}\".format(y_test.shape, y_test.dtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a model with the Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool box\n",
    "\n",
    "# some layers : \n",
    "from keras.layers import Input \n",
    "from keras.layers import Conv2D, Dense, Dropout, BatchNormalization\n",
    "from keras.layers import Activation, LeakyReLU\n",
    "from keras.layers import MaxPool2D, AveragePooling2D, Flatten, GlobalAveragePooling2D\n",
    "from keras.layers import Add, Concatenate\n",
    "\n",
    "# here : the functional API \n",
    "from keras.models import Model\n",
    "\n",
    "# some optimzers\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "\n",
    "# some keras callbacks to monitor the training\n",
    "from keras.callbacks import Callback,EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to add a 'fake' dimension for the 'gray' channel\n",
    "input_layer = Input(shape=(??,??,1??))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of neural networl (beginning)\n",
    "# 28x28 feature maps\n",
    "# x = Conv2D(filters=8, kernel_size=3, padding='same', strides=1, use_bias=False)(input_layer)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('relu')(x)\n",
    "# x = Conv2D(filters=16, kernel_size=3, padding='same', strides=2, use_bias=False)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('relu')(x)\n",
    "\n",
    "\n",
    "output_layer = ....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs= ??? , outputs=???)\n",
    "# we can use 'model' as a classical Sequential) model (.fit(), .predict(), .evaluate() ) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.1, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ReduceLROnPlateau.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add some callbacks\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', verbose=1, patience=3, min_delta=0.)\n",
    "\n",
    "redure_lr = ReduceLROnPlateau(monitor='val_loss', min_lr=1e-5, patience=1, verbose=1, factor=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [early_stop, redure_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 64\n",
    "verbose = 1 # do not set to 1 !! (issue with progbar with remore notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=callbacks,\n",
    "                    shuffle=True,\n",
    "                    verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(25,10))\n",
    "fig, ax_loss = plt.subplots(figsize=(25,10))\n",
    "\n",
    "ax_acc = ax_loss.twinx()\n",
    "ax_lr = ax_loss.twinx()\n",
    "\n",
    "ax_loss.plot(history.history['loss'], 'r')\n",
    "ax_loss.plot(history.history['val_loss'], 'g')\n",
    "ax_loss.set_xlabel('epochs')\n",
    "ax_loss.set_ylabel('loss')\n",
    "\n",
    "ax_acc.plot(history.history['acc'], 'r')\n",
    "ax_acc.plot(history.history['val_acc'], 'g')\n",
    "ax_acc.set_ylabel('accuracy')\n",
    "\n",
    "ax_lr.plot(history.history['lr'], 'b')\n",
    "ax_lr.set_ylabel('learning_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.evaluate(x_train, y_train, verbose=0))\n",
    "print(model.evaluate(x_val, y_val, verbose=0))\n",
    "print(model.evaluate(x_test, y_test, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
